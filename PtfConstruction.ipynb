{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19c3a5c8",
   "metadata": {},
   "source": [
    "# Analysis of S&P 500 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risk-free rate is assumed to be zero and the portfolios weights is therefor entirely in risky assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "04552fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc2d0f",
   "metadata": {},
   "source": [
    "Import tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6425fc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  503 of 503 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4 Failed downloads:\n",
      "['KVUE', 'VLTO']: Exception(\"%ticker%: Data doesn't exist for startDate = 946702800, endDate = 1672462800\")\n",
      "['BF.B']: Exception('%ticker%: No price data found, symbol may be delisted (1d 2000-01-01 -> 2022-12-31)')\n",
      "['BRK.B']: Exception('%ticker%: No timezone found, symbol may be delisted')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # Load the current list of S&P 500 companies\n",
    "# sp500_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "# sp500_table = pd.read_html(sp500_url, header=0)[0]\n",
    "\n",
    "# # Extracting the ticker symbols \n",
    "# sp500_tickers = sp500_table[\"Symbol\"].tolist()\n",
    "\n",
    "# # Define the time period\n",
    "# start_date = '2000-01-01'\n",
    "# end_date = '2022-12-31'\n",
    "\n",
    "# # Building a dataframe with stock prices for the companies\n",
    "# df = yf.download(sp500_tickers,start=start_date,end=end_date)\n",
    "# df = df['Adj Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data in sql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5787"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Seting up database for later use \n",
    "# SNP500_data = sqlite3.connect(database=\"SNP500_data.sqlite\")\n",
    "\n",
    "# (df.to_sql(name=\"SNP500_prices\", \n",
    "#           con=SNP500_data,  \n",
    "#           if_exists=\"replace\",\n",
    "#           index = True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from sql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNP500_data = sqlite3.connect(database=\"SNP500_data.sqlite\")\n",
    "\n",
    "prices = (pd.read_sql_query(sql=\"SELECT * FROM SNP500_prices\", con=SNP500_data, index_col=\"Date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers=[\"MMM\",\"AOS\",\"ABT\",\"ADM\",\"ADBE\",\"ADP\",\"AES\",\"AFL\",\"A\",\"AKAM\"]\n",
    "\n",
    "prices = prices[tickers]\n",
    "# Change the index column to be the date\n",
    "prices.index = pd.to_datetime(prices.index)\n",
    "\n",
    "# Extract the stock price at the end of each month from downloaded data\n",
    "prices_monthly = prices.resample(\"1M\").last()\n",
    "prices_monthly.index = prices_monthly.index.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4455ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop stocks with missing values\n",
    "prices_monthly = prices_monthly.dropna(how=\"all\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3fc29f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing log returns using np.log and shift, as well as removing the first row (since its NaN)\n",
    "ret = np.log(prices_monthly / prices_monthly.shift(1))[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of Mean-Variance Ptf vs. Global Minimum Ptf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7715f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal weights of MVP (tangency) portfolio without constraints:\n",
    "def MVP_w(returns):\n",
    "    ones = np.ones(len(returns.columns)) \n",
    "    mu = returns.mean()\n",
    "    var_cov = returns.cov()\n",
    "    numerator = np.linalg.inv(var_cov) @ mu\n",
    "    denominator = ones.T @ np.linalg.inv(var_cov) @ mu\n",
    "    optimal_weight = numerator/denominator\n",
    "    return optimal_weight\n",
    "\n",
    "# Optimal weights of GMV portfolio without constraints:\n",
    "def GMV_w(returns):\n",
    "    ones = np.ones(len(returns.columns)) \n",
    "    var_cov = returns.cov()\n",
    "    numerator = np.linalg.inv(var_cov) @ ones\n",
    "    denominator = ones.T @ np.linalg.inv(var_cov) @ ones\n",
    "    optimal_weight = numerator/denominator\n",
    "    return optimal_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVP_weights = pd.DataFrame(index = ret.index, columns =ret.columns)\n",
    "\n",
    "for i in ret.index[60:]: # require 5y of data \n",
    "    start_date = i - pd.DateOffset(months = 60)\n",
    "    end_date = i-pd.DateOffset(months = 1)\n",
    "    start_date = pd.to_datetime(start_date).date()\n",
    "    end_date = pd.to_datetime(end_date).date()\n",
    "    df = ret.loc[start_date:end_date]\n",
    "    MVP_weights.loc[i] = MVP_w(df) \n",
    "\n",
    "MVP_weights = MVP_weights.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMV portfolio:\n",
    "GMV_weights = pd.DataFrame(index = ret.index, columns =ret.columns)\n",
    "\n",
    "for i in ret.index[60:]: \n",
    "    start_date = i - pd.DateOffset(months = 60)\n",
    "    end_date = i - pd.DateOffset(months = 1)\n",
    "    start_date = pd.to_datetime(start_date).date()\n",
    "    end_date = pd.to_datetime(end_date).date()\n",
    "    df = ret.loc[start_date:end_date]\n",
    "    GMV_weights.loc[i] = GMV_w(df) \n",
    "\n",
    "GMV_weights = GMV_weights.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return on MVP and GMV portfolio without constraints:\n",
    "MVP_return = (MVP_weights * ret.iloc[60:]).sum(axis = 1)\n",
    "GMV_return = (GMV_weights * ret.iloc[60:]).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio(return_):             \n",
    "    Rf=0\n",
    "    m_mean_return = return_.mean()     \n",
    "    m_vol = return_.std()              \n",
    "    y_mean_return = m_mean_return * 12  \n",
    "    y_vol = m_vol * np.sqrt(12)         \n",
    "    SR = (y_mean_return-Rf)/y_vol\n",
    "    return SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annualized Sharpe ratio of MVP portfolio is -0.14067935252818148.\n",
      "Annualized Sharpe Ratio of GMV portfolio is 0.6918133195127342.\n"
     ]
    }
   ],
   "source": [
    "# Sharpe ratio for MVP portfolio:\n",
    "print(f'Annualized Sharpe ratio of MVP portfolio is {sharpe_ratio(MVP_return)}.')\n",
    "# Sharpe ratio for GMV portfolio:\n",
    "print(f'Annualized Sharpe Ratio of GMV portfolio is {sharpe_ratio(GMV_return)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrained Mean-Variance Ptf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective to be minimized (portfolio variance)\n",
    "def objective_MVP(weights, mu, V):\n",
    "    portfolio_return = weights.T @ mu\n",
    "    portfolio_variance = weights.T @ V @ weights\n",
    "    sharpe = portfolio_return/np.sqrt(portfolio_variance)\n",
    "    return -sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the optimal weight of MVP-C portfolio:\n",
    "def MVP_C_w(returns):\n",
    "    mu = returns.mean()\n",
    "    V = returns.cov()\n",
    "\n",
    "    # Define the constraint that the weights sum to 1\n",
    "    constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights)- 1})\n",
    "\n",
    "    # Define the bounds for each weight (0 <= weight <= 999)\n",
    "    bounds = tuple((0, 999) for _ in range(len(V)))\n",
    "\n",
    "    # Define the initial guess for weights\n",
    "    initial_weights = np.ones(len(V)) / len(V)\n",
    "\n",
    "    # Use scipy.optimize.minimize to find the optimal weights\n",
    "    result = minimize(objective_MVP, initial_weights, args = (mu,V,), method = 'SLSQP',bounds = bounds, constraints = constraints)\n",
    "\n",
    "    # Extract the optimal weights\n",
    "    optimal_weights = result.x\n",
    "    return optimal_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVP_C_weights = pd.DataFrame(index=ret.index, columns=ret.columns)\n",
    "for i in ret.index[60:]:    \n",
    "    start_date = i - pd.DateOffset(months=60)\n",
    "    end_date = i-pd.DateOffset(months=1)\n",
    "    start_date = pd.to_datetime(start_date).date()\n",
    "    end_date=pd.to_datetime(end_date).date()\n",
    "    df = ret.loc[start_date:end_date]\n",
    "\n",
    "    # calculate MVP-C portfolio for each rolling window\n",
    "    MVP_C_weights.loc[i] = MVP_C_w(df)\n",
    "    \n",
    "MVP_C_weights = MVP_C_weights.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrained Global Minimum Ptf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective to be minimized (portfolio variance)\n",
    "def objective_GMV(weights, V):\n",
    "    portfolio_variance = weights.T @ V @ weights\n",
    "    return portfolio_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the optimal weight of GMV-C portfolio:\n",
    "def GMV_C_w(returns):\n",
    "    V = returns.cov()\n",
    "    # Define the constraint that the weights sum to 1\n",
    "    constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})\n",
    "\n",
    "    # Define the bounds for each weight (0 <= weight <= 999)\n",
    "    bounds = tuple((0, 999) for _ in range(len(V)))\n",
    "\n",
    "    # Define the initial guess for the weights\n",
    "    initial_weights = np.ones(len(V)) / len(V)\n",
    "\n",
    "    # Use scipy.optimize.minimize to find the optimal weights\n",
    "    result = minimize(objective_GMV, initial_weights, args=(V,), method='SLSQP',bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    # Extract the optimal weights\n",
    "    optimal_weights = result.x\n",
    "    return optimal_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMV_C_weights = pd.DataFrame(index = ret.index, columns =ret.columns)\n",
    "\n",
    "for i in ret.index[60:]:#start from the 61th month\n",
    "    start_date = i - pd.DateOffset(months = 60)\n",
    "    end_date = i-pd.DateOffset(months = 1)\n",
    "    start_date = pd.to_datetime(start_date).date()\n",
    "    end_date = pd.to_datetime(end_date).date()\n",
    "    \n",
    "    df = ret.loc[start_date:end_date]\n",
    "\n",
    "    # calculate GMV-C portfolio for each rolling window\n",
    "    GMV_C_weights.loc[i] = GMV_C_w(df)\n",
    "\n",
    "GMV_C_weights=GMV_C_weights.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return on MVP-C portfolio with non-negative constraints:\n",
    "MVP_C_return = (MVP_C_weights * ret.iloc[60:]).sum(axis = 1)\n",
    "\n",
    "# Return on GMV-C portfolio with non-negative constraints:\n",
    "GMV_C_return = (GMV_C_weights * ret.iloc[60:]).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio of MVP-C portfolio with non-negative constraints is 0.6314021927686365.\n",
      "Sharpe Ratio of GMV-C portfolio with non-negative constraints is 0.6790103409313136.\n"
     ]
    }
   ],
   "source": [
    "# Sharpe ratio for MVP-C portfolio with constraints:\n",
    "print(f'Sharpe Ratio of MVP-C portfolio with non-negative constraints is {sharpe_ratio(MVP_C_return)}.')\n",
    "# Sharpe ratio for GMV-C portfolio with constraints:\n",
    "print(f'Sharpe Ratio of GMV-C portfolio with non-negative constraints is {sharpe_ratio(GMV_C_return)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
